apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: SERVICE_ID_PLACEHOLDER
  namespace: default
  labels:
    yunikorn.apache.org/app-id: "SERVICE_ID_PLACEHOLDER"
    build-number: "BUILD_NUMBER"
spec:
  type: Scala
  mode: cluster
  image: docker.io/library/spark:BUILD_NUMBER
  imagePullPolicy: IfNotPresent
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: local:///opt/spark/examples/jars/spark-examples.jar
  sparkVersion: 4.0.1
  driver:
    cores: 1
    memory: 512m
    podName: "SERVICE_ID_PLACEHOLDER"
    labels:
      yunikorn.apache.org/app-id: "SERVICE_ID_PLACEHOLDER"
      build-number: "BUILD_NUMBER"
    annotations:
      # 1. Driver 자신이 속할 그룹 이름
      yunikorn.apache.org/task-group-name: "spark-driver"
      yunikorn.apache.org/task-groups: |-
        [
          {
            "name": "spark-driver",
            "minMember": 1,
            "minResource": {
              "cpu": "100m",
              "memory": "512Mi"
            },
            "nodeSelector": {},
            "tolerations": []
          },
          {
            "name": "spark-executor",
            "minMember": 1,
            "minResource": {
              "cpu": "100m",
              "memory": "512Mi"
            },
            "nodeSelector": {},
            "tolerations": []
          }
        ]
    serviceAccount: spark-operator-spark
    template:
      spec:
        containers:
          - name: SERVICE_ID_PLACEHOLDER
            image: docker.io/library/spark:BUILD_NUMBER
            resources:
              limits:
                memory: 512m
                cpu: "1"
              requests:
                memory: 512m
                cpu: "500m"
    securityContext:
      capabilities:
        drop:
        - ALL
      runAsGroup: 185
      runAsUser: 185
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault
  executor:
    instances: 1
    cores: 1
    memory: 512m
    labels:
      yunikorn.apache.org/app-id: "SERVICE_ID_PLACEHOLDER"
      build-number: "BUILD_NUMBER"
    annotations:
      # Executor가 속한 그룹 이름 지정
      yunikorn.apache.org/task-group-name: "spark-executor"
    template:
      spec:
        containers:
          - name: SERVICE_ID_PLACEHOLDER
            image: docker.io/library/spark:BUILD_NUMBER
            resources:
              limits:
                memory: 512m
                cpu: "1"
              requests:
                memory: 512m
                cpu: "500m"
    securityContext:
      capabilities:
        drop:
        - ALL
      runAsGroup: 185
      runAsUser: 185
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault
  sparkConf:
    spark.app.name: "SERVICE_ID_PLACEHOLDER"
    spark.kubernetes.executor.podNamePrefix: "SERVICE_ID_PLACEHOLDER"
    spark.kubernetes.driver.pod.name: "SERVICE_ID_PLACEHOLDER"
    # Disable dynamic allocation to keep executors alive longer
    spark.dynamicAllocation.enabled: "false"
    spark.dynamicAllocation.shuffleTracking.enabled: "false"

  # SparkApplication 객체 종료 후 1시간(3600초) 동안 유지
  # 참고: v1beta2 API에서는 파드 보존(cleanPodPolicy) 필드가 없음
  timeToLiveSeconds: 3600

  batchScheduler: yunikorn
  batchSchedulerOptions:
    queue: root.default
